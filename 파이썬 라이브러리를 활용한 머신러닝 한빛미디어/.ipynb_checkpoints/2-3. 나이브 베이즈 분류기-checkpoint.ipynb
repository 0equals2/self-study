{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#나이브-베이즈-분류기\" data-toc-modified-id=\"나이브-베이즈-분류기-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>나이브 베이즈 분류기</a></span><ul class=\"toc-item\"><li><span><a href=\"#나이브-베이즈-분류기\" data-toc-modified-id=\"나이브-베이즈-분류기-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>나이브 베이즈 분류기</a></span></li><li><span><a href=\"#장단점과-매개변수\" data-toc-modified-id=\"장단점과-매개변수-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>장단점과 매개변수</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 나이브 베이즈 분류기\n",
    "## 나이브 베이즈 분류기\n",
    "나이브 베이즈 naive bayes 분류기는 선형 모델과 매우 유사하다. LogisticRegression 이나 LinearSVC 같은 선형 분류기보다 훈련 속도가 빠르다. 대신 일반화 성능이 조금 떨어진다.\n",
    "\n",
    "나이브 베이즈 분류기가 효과적인 이유는 각 특성을 개별로 취급해 파라미터를 학습하고 각 특성에서 클래스별 통계를 **단순하게 취합**하기 때문이다. 사이킷런에 구현된 나이브 베이즈 분류기는 **GaussianNB, BernoulliNB, MultinomialNB** 세 가지이다. 가우시안NB는 **연속적인 어떤 데이터**에도 적용할 수 있고 베르누이NB는 **이진 데이터**를, 멀티노미얼NB는 **카운트 데이터** (특성이 어떤 것을 헤아린 정수 카운트로, 예를 들어 문장에 나타난 단어의 횟수)에 적용된다. 베르누이NB, 멀티노미얼NB는 대부분 텍스트 데이터를 분류할 때 사용한다.\n",
    "\n",
    "베르누이NB 분류기는 각 클래스의 특성 중 0이 아닌 것이 몇 개인지 센다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T08:28:22.578190Z",
     "start_time": "2019-09-25T08:28:22.571189Z"
    }
   },
   "outputs": [],
   "source": [
    "X = np.array([[0, 1, 0, 1],\n",
    "                 [1, 0, 1, 1],\n",
    "                 [0, 0, 0, 1],\n",
    "                 [1, 0, 1, 0]])\n",
    "y = np.array([0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이진 특성을 4개 가진 데이터 포인트가 4개 있다. 클래스는 0과 1, 두 개이다. 출력 y의 클래스가 0인 경우, 첫 번재 특성은 0 이 두 번이고 0이 아닌 것은 한 번도 없다. 두 번째 특성은 0이 한 번이고 1도 한 번이다. 같은 방식으로 두 번째 클래스에 해당하는 데이터 포인트에 대해서도 계산한다. 클래스별로 0이 아닌 원소를 세는 과정을 요약하면 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T08:32:17.030694Z",
     "start_time": "2019-09-25T08:32:17.025695Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: array([0, 1, 0, 2]), 1: array([2, 0, 2, 1])}\n"
     ]
    }
   ],
   "source": [
    "counts= {}\n",
    "for label in np.unique(y):\n",
    "    #클래스마다 반속\n",
    "    # 특성마다 1이 나타난 횟수를 센다.\n",
    "    counts[label] = X[y== label].sum(axis=0)\n",
    "print(counts)#특성카운트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다른 두 나이브 베이즈 모델 MultinomialNB와 GaussianNB는 계산하는 통계 데이터의 종류가 조금 다르다. **MultinomialNB는 클래스별로 특성의 평균을 계산하고 GaussianNB는 클래스별로 각 특성의 표준편차와 평균을 저장**한다.\n",
    "\n",
    "예측할 땐 데이터 포인트를 클래스의 통계 값과 비교해서 가장 잘 맞는 클래스를 예측값으로 한다. MultinomialNB와 BernoulliNB의 예측 공식은 선형 모델과 형태가 같다. 그러나 나이브 베이즈 모델의 coef_는 기울기 w가 아니라서 선형 모델과는 의미가 다르다.\n",
    "\n",
    "## 장단점과 매개변수\n",
    "MultinomialNB와 BernoulliNB는 모델의 복잡도를 조절하는 **alpha 매개변수** 하나를 가지고 있다. alpha 가 주어지면 알고리즘이 모든 특성에 양의 값을 가진 **가상의 데이터 포인트**를 **alpha 개수만큼 추가**한다. 이는 통계 데이터를 완만하게 만들어준다. alpha가 크면 더 완만해지고 모델의 복잡도는 낮아진다. alpha에 따른 알고리즘 성능 변동은 비교적 크지 않아서, alpha 값이 성능 향상에 크게 기여하지 않는다. 그러나 이 값을 조정하면 어느 정도는 정확도를 높일 수 있다.\n",
    "\n",
    "GaussianNB는 대부분 매우 고차원인 데이터셋에 사용하고, 다른 두 나이브 베이즈 모델은 텍스트 같은 희소한 데이터를 카운트하는 데 사용한다. **MultinomialNB는 보통 0이 아닌 특성이 비교적 많은 데이터셋** (예를 들면 큰 문서들) 에서 BernoulliNB보다 성능이 높다.\n",
    "\n",
    "나이브 베이즈 모델과 선형 모델의 장단점은 비슷하다. 훈련과 예측 속도가 빠르며 훈련 과정을 이해하기 쉽다. 희소한 고차원 데이터에서 잘 작동하며 비교적 매개변수에 민감하지 않다. 선형 모델로는 학습 시간이 너무 오래 걸리는 매우 큰 데이터셋에는 나이브 베이즈 모델을 시도해볼 만하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
